{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3039a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "from jax import random\n",
    "import math\n",
    "from typing import Callable\n",
    "import os\n",
    "from flax.training import train_state\n",
    "import orbax.checkpoint\n",
    "import optax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "645c3fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import flax\n",
    "except ModuleNotFoundError:  # Install flax if missing\n",
    "    !pip install --quiet flax\n",
    "    import flax\n",
    "\n",
    "from flax import linen as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0bee98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': TrainState(step=1, apply_fn=<bound method Module.apply of Dense(\n",
       "     # attributes\n",
       "     features = 3\n",
       "     use_bias = True\n",
       "     dtype = None\n",
       "     param_dtype = float32\n",
       "     precision = None\n",
       "     kernel_init = init\n",
       "     bias_init = zeros\n",
       "     promote_dtype = promote_dtype\n",
       "     dot_general = None\n",
       "     dot_general_cls = None\n",
       " )>, params={'bias': Array([-0.001, -0.001, -0.001], dtype=float32), 'kernel': Array([[-0.14771505, -0.21384335,  0.11710571],\n",
       "        [-0.45254678, -0.0309354 ,  0.42556357],\n",
       "        [-0.15834738, -0.47992307,  0.4152557 ],\n",
       "        [-0.72053933, -0.52988744, -0.44720745],\n",
       "        [-0.27621508, -0.25154397,  0.03122341]], dtype=float32)}, tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x12ab07ce0>, update=<function chain.<locals>.update_fn at 0x12ab07060>), opt_state=(EmptyState(), EmptyState())),\n",
       " 'config': {'dimensions': Array([5, 3], dtype=int32)},\n",
       " 'data': [Array([ 1.0040143, -0.9063372, -0.7481722, -1.1713669, -0.8712328],      dtype=float32)]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple model with one linear layer.\n",
    "key1, key2 = random.split(random.key(0))\n",
    "x1 = random.normal(key1, (5,))      # A simple JAX array.\n",
    "model = nn.Dense(features=3)\n",
    "variables = model.init(key2, x1)\n",
    "\n",
    "# Flax's TrainState is a pytree dataclass and is supported in checkpointing.\n",
    "# Define your class with `@flax.struct.dataclass` decorator to make it compatible.\n",
    "tx = optax.sgd(learning_rate=0.001)      # An Optax SGD optimizer.\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=variables['params'],\n",
    "    tx=tx)\n",
    "# Perform a simple gradient update similar to the one during a normal training workflow.\n",
    "state = state.apply_gradients(grads=jax.tree_util.tree_map(jnp.ones_like, state.params))\n",
    "\n",
    "# Some arbitrary nested pytree with a dictionary and a NumPy array.\n",
    "config = {'dimensions': np.array([5, 3])}\n",
    "\n",
    "# Bundle everything together.\n",
    "ckpt = {'model': state, 'config': config, 'data': [x1]}\n",
    "ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8980cb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:[process=0][thread=MainThread] Skipped cross-host ArrayMetadata validation because only one process is found: process_index=0.\n"
     ]
    }
   ],
   "source": [
    "from flax.training import orbax_utils\n",
    "\n",
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "save_args = orbax_utils.save_args_from_target(ckpt)\n",
    "path = os.path.abspath('./tmp/flax_ckpt/orbax/single_save')\n",
    "orbax_checkpointer.save(path, ckpt, save_args=save_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "824dc727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0', '4', '3']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options = orbax.checkpoint.CheckpointManagerOptions(max_to_keep=2, create=True)\n",
    "path2 = os.path.abspath('./tmp/flax_ckpt/orbax/managed')\n",
    "checkpoint_manager = orbax.checkpoint.CheckpointManager(\n",
    "    path2, orbax_checkpointer, options)\n",
    "\n",
    "# Inside a training loop\n",
    "for step in range(5):\n",
    "    # ... do your training\n",
    "    checkpoint_manager.save(step, ckpt, save_kwargs={'save_args': save_args})\n",
    "\n",
    "os.listdir(path2)  # Because max_to_keep=2, only step 3 and 4 are"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
