{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8443f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf')\n",
    "from matplotlib.colors import to_rgba\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#progress bar\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8505bc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using jax 0.6.0\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "print(\"Using jax\", jax.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67d7e354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "a = jnp.zeros((2,5), dtype=jnp.float32)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "129ede14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "b = jnp.arange(6)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "958fccfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jaxlib.xla_extension.ArrayImpl"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa469235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CpuDevice(id=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd87030c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "b_cpu = jax.device_get(b)\n",
    "print(b_cpu.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66366c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CpuDevice(id=0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaca11ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.at[0].set(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c31d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e923ba78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/jax_intro/lib/python3.11/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import flax\n",
    "except ModuleNotFoundError: # Install flax if missing\n",
    "    !pip install --quiet flax\n",
    "    import flax\n",
    "\n",
    "from flax import linen as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6403d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    num_hidden : int   # Number of hidden neurons\n",
    "    num_outputs : int  # Number of output neurons\n",
    "\n",
    "    def setup(self):\n",
    "        # Create the modules we need to build the network\n",
    "        # nn.Dense is a linear layer\n",
    "        self.linear1 = nn.Dense(features=self.num_hidden)\n",
    "        self.linear2 = nn.Dense(features=self.num_outputs)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # Perform the calculation of the model to determine the prediction\n",
    "        x = self.linear1(x)\n",
    "        x = nn.tanh(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783403a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifierCompact(nn.Module):\n",
    "    num_hidden : int   # Number of hidden neurons\n",
    "    num_outputs : int  # Number of output neurons\n",
    "\n",
    "    @nn.compact  # Tells Flax to look for defined submodules\n",
    "    def __call__(self, x):\n",
    "        # Perform the calculation of the model to determine the prediction\n",
    "        # while defining necessary layers\n",
    "        x = nn.Dense(features=self.num_hidden)(x)\n",
    "        x = nn.tanh(x)\n",
    "        x = nn.Dense(features=self.num_outputs)(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07d1dfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleClassifier(\n",
      "    # attributes\n",
      "    num_hidden = 8\n",
      "    num_outputs = 1\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleClassifier(num_hidden=8, num_outputs=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7e39863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'params': {'linear1': {'kernel': Array([[-1.4184448 , -0.13778795,  0.01538001, -0.16879076, -0.04171572,\n",
      "        -0.13396461,  1.3444221 ,  0.3372816 ],\n",
      "       [-0.88903946, -0.36091748, -0.41084424,  1.3910713 ,  1.4182491 ,\n",
      "        -0.68443036, -0.84274894,  1.0029515 ]], dtype=float32), 'bias': Array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)}, 'linear2': {'kernel': Array([[ 0.06771415],\n",
      "       [ 0.3815392 ],\n",
      "       [-0.44763517],\n",
      "       [ 0.10989622],\n",
      "       [-0.12707736],\n",
      "       [ 0.03953529],\n",
      "       [-0.51339453],\n",
      "       [ 0.33707327]], dtype=float32), 'bias': Array([0.], dtype=float32)}}}\n"
     ]
    }
   ],
   "source": [
    "rng, inp_rng, init_rng = jax.random.split(rng, 3)\n",
    "inp = jax.random.normal(inp_rng, (8, 2))  # Batch size 8, input size 2\n",
    "# Initialize the model\n",
    "params = model.init(init_rng, inp)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bba2b35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.08598191],\n",
       "       [ 0.18361846],\n",
       "       [ 0.23252794],\n",
       "       [-0.41932803],\n",
       "       [ 0.09644738],\n",
       "       [ 0.02926508],\n",
       "       [-0.44354892],\n",
       "       [-0.4412725 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(params,inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2bc748f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "052def96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XORDataset(data.Dataset):\n",
    "    def __init__(self, size, seed, std=0.1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            size - Number of data points we want to generate\n",
    "            seed - The seed to use to create the PRNG state with which we want to generate the data points\n",
    "            std - Standard deviation of the noise (see generate_continuous_xor function)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.np_rng = np.random.RandomState(seed=seed)\n",
    "        self.std = std\n",
    "        self.generate_continuous_xor()\n",
    "\n",
    "    def generate_continuous_xor(self):\n",
    "        # Each data point in the XOR dataset has two variables, x and y, that can be either 0 or 1\n",
    "        # The label is their XOR combination, i.e. 1 if only x or only y is 1 while the other is 0.\n",
    "        # If x=y, the label is 0.\n",
    "        data = self.np_rng.randint(low=0, high=2, size=(self.size, 2)).astype(np.float32)\n",
    "        label = (data.sum(axis=1) == 1).astype(np.int32)\n",
    "        # To make it slightly more challenging, we add a bit of gaussian noise to the data points.\n",
    "        data += self.np_rng.normal(loc=0.0, scale=self.std, size=data.shape)\n",
    "\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return the idx-th data point of the dataset\n",
    "        # If we have multiple things to return (data point and label), we can return them as tuple\n",
    "        data_point = self.data[idx]\n",
    "        data_label = self.label[idx]\n",
    "        return data_point, data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5612b483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 200\n",
      "Data point 0: (array([-0.06800247,  1.0232254 ], dtype=float32), np.int32(1))\n"
     ]
    }
   ],
   "source": [
    "dataset = XORDataset(size=200, seed=42)\n",
    "print(\"Size of dataset:\", len(dataset))\n",
    "print(\"Data point 0:\", dataset[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de9a2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This collate function is taken from the JAX tutorial with PyTorch Data Loading\n",
    "# https://jax.readthedocs.io/en/latest/notebooks/Neural_Network_and_Data_Loading.html\n",
    "def numpy_collate(batch):\n",
    "    if isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple,list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)\n",
    "\n",
    "data_loader = data.DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=numpy_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea18e6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inputs (8, 2) \n",
      " [[ 1.0058209  -0.11429703]\n",
      " [ 0.08356921 -0.11297069]\n",
      " [-0.10676204 -0.01423795]\n",
      " [ 0.9730593   1.0717542 ]\n",
      " [ 0.02930725 -0.07143514]\n",
      " [ 0.9281556   0.9786553 ]\n",
      " [ 1.1628616  -0.13801014]\n",
      " [ 0.9243649  -0.14222537]]\n",
      "Data labels (8,) \n",
      " [1 0 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# next(iter(...)) catches the first batch of the data loader\n",
    "# If shuffle is True, this will return a different batch every time we run this cell\n",
    "# For iterating over the whole dataset, we can simple use \"for batch in data_loader: ...\"\n",
    "data_inputs, data_labels = next(iter(data_loader))\n",
    "\n",
    "# The shape of the outputs are [batch_size, d_1,...,d_N] where d_1,...,d_N are the\n",
    "# dimensions of the data point returned from the dataset class\n",
    "print(\"Data inputs\", data_inputs.shape, \"\\n\", data_inputs)\n",
    "print(\"Data labels\", data_labels.shape, \"\\n\", data_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9ec251c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import optax\n",
    "except ModuleNotFoundError: # Install optax if missing\n",
    "    !pip install --quiet optax\n",
    "    import optax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27f10bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input to the optimizer are optimizer settings like learning rate\n",
    "optimizer = optax.sgd(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "569293f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training import train_state\n",
    "\n",
    "model_state = train_state.TrainState.create(apply_fn=model.apply,\n",
    "                                            params=params,\n",
    "                                            tx=optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ba60533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss_acc(state, params, batch):\n",
    "    data_input, labels = batch\n",
    "    # Obtain the logits and predictions of the model for the input data\n",
    "    logits = state.apply_fn(params, data_input).squeeze(axis=-1)\n",
    "    pred_labels = (logits > 0).astype(jnp.float32)\n",
    "    # Calculate the loss and accuracy\n",
    "    loss = optax.sigmoid_binary_cross_entropy(logits, labels).mean()\n",
    "    acc = (pred_labels == labels).mean()\n",
    "    return loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18c86c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.66125613, dtype=float32), Array(0.75, dtype=float32))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(data_loader))\n",
    "calculate_loss_acc(model_state, model_state.params, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "893de833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss_acc(state, params, batch):\n",
    "    data_input, labels = batch\n",
    "    # Obtain the logits and predictions of the model for the input data\n",
    "    logits = state.apply_fn(params, data_input).squeeze(axis=-1)\n",
    "    pred_labels = (logits > 0).astype(jnp.float32)\n",
    "    # Calculate the loss and accuracy\n",
    "    loss = optax.sigmoid_binary_cross_entropy(logits, labels).mean()\n",
    "    acc = (pred_labels == labels).mean()\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0bcd05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.6267252, dtype=float32), Array(0.875, dtype=float32))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(data_loader))\n",
    "calculate_loss_acc(model_state, model_state.params, batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10673172",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit  # Jit the function for efficiency\n",
    "def train_step(state, batch):\n",
    "    # Gradient function\n",
    "    grad_fn = jax.value_and_grad(calculate_loss_acc,  # Function to calculate the loss\n",
    "                                 argnums=1,  # Parameters are second argument of the function\n",
    "                                 has_aux=True  # Function has additional outputs, here accuracy\n",
    "                                )\n",
    "    # Determine gradients for current model, parameters and batch\n",
    "    (loss, acc), grads = grad_fn(state, state.params, batch)\n",
    "    # Perform parameter update with gradients and optimizer\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    # Return state and any other value we might want\n",
    "    return state, loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eaaa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit  # Jit the function for efficiency\n",
    "def eval_step(state, batch):\n",
    "    # Determine the accuracy\n",
    "    _, acc = calculate_loss_acc(state, state.params, batch)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "22a88c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = XORDataset(size=2500, seed=42)\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=numpy_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87598762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(state, data_loader, num_epochs=100):\n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for batch in data_loader:\n",
    "            state, loss, acc = train_step(state, batch)\n",
    "            # We could use the loss and accuracy for logging here, e.g. in TensorBoard\n",
    "            # For simplicity, we skip this part here\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "58432aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "100%|██████████| 100/100 [00:00<00:00, 151.49it/s]\n"
     ]
    }
   ],
   "source": [
    "trained_model_state = train_model(model_state, train_data_loader, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "717029d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = XORDataset(size=500, seed=123)\n",
    "# drop_last -> Don't drop the last batch although it is smaller than 128\n",
    "test_data_loader = data.DataLoader(test_dataset,\n",
    "                                   batch_size=128,\n",
    "                                   shuffle=False,\n",
    "                                   drop_last=False,\n",
    "                                   collate_fn=numpy_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac52e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(state, data_loader):\n",
    "    all_accs, batch_sizes = [], []\n",
    "    for batch in data_loader:\n",
    "        batch_acc = eval_step(state, batch)\n",
    "        all_accs.append(batch_acc)\n",
    "        batch_sizes.append(batch[0].shape[0])\n",
    "    # Weighted average since some batches might be smaller\n",
    "    acc = sum([a*b for a,b in zip(all_accs, batch_sizes)]) / sum(batch_sizes)\n",
    "    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2e580be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 100.00%\n"
     ]
    }
   ],
   "source": [
    "eval_model(trained_model_state, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4abbfae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = model.bind(trained_model_state.params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
