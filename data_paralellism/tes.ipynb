{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6d11a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "# Github URL where python scripts are stored.\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/uvadlc_notebooks/master/docs/tutorial_notebooks/scaling/JAX/\"\n",
    "# Files to download.\n",
    "python_files = [\"single_gpu.py\", \"utils.py\"]\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "for file_name in python_files:\n",
    "    if not os.path.isfile(file_name):\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"Downloading {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_name)\n",
    "        except HTTPError as e:\n",
    "            print(\n",
    "                \"Something went wrong. Please try to download the file directly from the GitHub repository, or contact the author with the full output including the following error:\\n\",\n",
    "                e,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7d6dde97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import simulate_CPU_devices\n",
    "\n",
    "simulate_CPU_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "fcff633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from pprint import pprint\n",
    "from typing import Any, Callable, Dict, Sequence, Tuple\n",
    "\n",
    "import flax.linen as nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "from absl import logging\n",
    "from jax import lax\n",
    "from jax.experimental.shard_map import shard_map\n",
    "from jax.sharding import Mesh\n",
    "from jax.sharding import PartitionSpec as P\n",
    "from ml_collections import ConfigDict\n",
    "from flax.training import train_state\n",
    "from single_gpu import TrainState\n",
    "\n",
    "PyTree = Any\n",
    "Metrics = Dict[str, Tuple[jax.Array, ...]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "670921d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPClassifier(nn.Module):\n",
    "    config: ConfigDict\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: jax.Array, train: bool) -> jax.Array:\n",
    "        x = nn.Dense(\n",
    "            features=self.config.hidden_size,\n",
    "            dtype=self.config.dtype,\n",
    "            name=\"input_dense\",\n",
    "        )(x)\n",
    "        x = nn.silu(x)\n",
    "        x = nn.Dropout(rate=self.config.dropout_rate, deterministic=not train)(x)\n",
    "        x = nn.Dense(\n",
    "            features=self.config.num_classes,\n",
    "            dtype=self.config.dtype,\n",
    "            name=\"output_dense\",\n",
    "        )(x)\n",
    "        x = x.astype(jnp.float32)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "19a3512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = ConfigDict(\n",
    "    dict(\n",
    "        batch_size=128,\n",
    "        num_classes=8,\n",
    "        input_size=784,\n",
    "    )\n",
    ")\n",
    "model_config = ConfigDict(\n",
    "    dict(\n",
    "        hidden_size=512,\n",
    "        dropout_rate=0.1,\n",
    "        dtype=jnp.bfloat16,\n",
    "        num_classes=data_config.num_classes,\n",
    "        data_axis_name=\"data\",\n",
    "    )\n",
    ")\n",
    "optimizer_config = ConfigDict(\n",
    "    dict(\n",
    "        learning_rate=1e-3,\n",
    "        num_minibatches=4,\n",
    "    )\n",
    ")\n",
    "config = ConfigDict(\n",
    "    dict(\n",
    "        model=model_config,\n",
    "        optimizer=optimizer_config,\n",
    "        data=data_config,\n",
    "        data_axis_name=model_config.data_axis_name,\n",
    "        seed=42,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f38294f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyState:\n",
    "    def __init__(self, base_key: jax.random.key):\n",
    "        self.key = jax.random.key(base_key)\n",
    "\n",
    "    def __call__(self, num: int = 2):\n",
    "        self.key, rng = jax.random.split(self.key, num=num)\n",
    "        return rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "627dff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DPClassifier(config=config.model)\n",
    "optimizer = optax.adamw(\n",
    "    learning_rate=config.optimizer.learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0de821f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = KeyState(config.seed)\n",
    "x=jax.random.normal(key(), (config.data.batch_size, config.data.input_size))\n",
    "y = jax.random.randint(key(), (config.data.batch_size,), 0, config.data.num_classes)\n",
    "variables = model.init({\"params\": key()}, x, train=False)\n",
    "params = variables.pop(\"params\")\n",
    "device_array = np.array(jax.devices())\n",
    "mesh = Mesh(device_array, (\"x\",))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "95b76ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_device(params, rng, local_model, config):\n",
    "        lr_scheduler = optax.warmup_cosine_decay_schedule(\n",
    "        init_value=0.2,\n",
    "        peak_value=0.5,\n",
    "        warmup_steps=15,\n",
    "        decay_steps=300,\n",
    "        end_value=0.9,\n",
    "        )   \n",
    "        tx = optax.chain(\n",
    "            optax.clip_by_global_norm(1),\n",
    "            optax.inject_hyperparams(optax.adam)(learning_rate=lr_scheduler),\n",
    "        )\n",
    "        state = TrainState.create(\n",
    "            apply_fn=local_model.apply,\n",
    "            params=params,\n",
    "            tx=tx,\n",
    "            rng=rng,\n",
    "        )\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "2eba59ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharded_init = shard_map(\n",
    "            functools.partial(init_device, rng=key(), local_model=model, config=model_config),\n",
    "            mesh,\n",
    "            in_specs=(P()),\n",
    "            out_specs=(P()),\n",
    "        )\n",
    "\n",
    "state_initialized = sharded_init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "179ed13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_key(key, axis):\n",
    "        axis_index = jax.lax.axis_index(axis)\n",
    "        return jax.random.fold_in(key, axis_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e823176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(model, params, key, x, y, train=True):\n",
    "        dropout_key = fold_key(key, config.data_axis_name)\n",
    "        B, T = x.shape\n",
    "        pred = model.apply({'params': params}, x, train=train, rngs={'dropout': key})\n",
    "        log_prob = jax.nn.log_softmax(pred, axis=-1)\n",
    "        loss = -jnp.mean(log_prob[jnp.arange(B), y])\n",
    "        return loss\n",
    "#loss = cross_entropy_loss(model, params, key(), x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "f95bec2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP Parameters\n",
      "{'input_dense': {'bias': ((512,),\n",
      "                          NamedSharding(mesh=Mesh('x': 8, axis_types=(Auto,)), spec=PartitionSpec(), memory_kind=unpinned_host)),\n",
      "                 'kernel': ((784, 512),\n",
      "                            NamedSharding(mesh=Mesh('x': 8, axis_types=(Auto,)), spec=PartitionSpec(), memory_kind=unpinned_host))},\n",
      " 'output_dense': {'bias': ((8,),\n",
      "                           NamedSharding(mesh=Mesh('x': 8, axis_types=(Auto,)), spec=PartitionSpec(), memory_kind=unpinned_host)),\n",
      "                  'kernel': ((512, 8),\n",
      "                             NamedSharding(mesh=Mesh('x': 8, axis_types=(Auto,)), spec=PartitionSpec(), memory_kind=unpinned_host))}}\n"
     ]
    }
   ],
   "source": [
    "print(\"DP Parameters\")\n",
    "pprint(jax.tree.map(lambda x: (x.shape, x.sharding), state_initialized.params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
